diff --git a/alembic.ini b/alembic.ini
index d8ce1ba..de9f5b3 100644
--- a/alembic.ini
+++ b/alembic.ini
@@ -6,7 +6,7 @@
 # format, relative to the token %(here)s which refers to the location of this
 # ini file
 script_location = alembic
-sqlalchemy.url = postgresql://test_user:test_password@localhost:5433/test_db
+sqlalchemy.url = %(PRAXIS_DATABASE_URL)s
 
 
 [post_write_hooks]
diff --git a/alembic/env.py b/alembic/env.py
index 27efe08..178b17f 100644
--- a/alembic/env.py
+++ b/alembic/env.py
@@ -1,9 +1,9 @@
 from logging.config import fileConfig
 
-from sqlalchemy import engine_from_config, pool
+from sqlalchemy import engine_from_config
+from sqlalchemy import pool
 
 from alembic import context
-from praxis.backend.utils.db import Base as PraxisBase
 
 # this is the Alembic Config object, which provides
 # access to the values within the .ini file in use.
@@ -12,70 +12,80 @@ config = context.config
 # Interpret the config file for Python logging.
 # This line sets up loggers basically.
 if config.config_file_name is not None:
-  fileConfig(config.config_file_name)
+    fileConfig(config.config_file_name)
 
-# --- MODIFICATION FOR PRAXIS ---
-target_metadata = PraxisBase.metadata  # Use the Base from your application
-# --- END MODIFICATION ---
+# add your model's MetaData object here
+# for 'autogenerate' support
+# from myapp import mymodel
+# target_metadata = mymodel.Base.metadata
+target_metadata = None
+
+# other values from the config, defined by the needs of env.py,
+# can be acquired:
+# my_important_option = config.get_main_option("my_important_option")
+# ... etc.
 
 
 def run_migrations_offline() -> None:
-  """Run migrations in 'offline' mode.
+    """Run migrations in 'offline' mode.
 
-  This configures the context with just a URL
-  and not an Engine, though an Engine is acceptable
-  here as well.  By skipping the Engine creation
-  we don't even need a DBAPI to be available.
+    This configures the context with just a URL
+    and not an Engine, though an Engine is acceptable
+    here as well.  By skipping the Engine creation
+    we don't even need a DBAPI to be available.
 
-  Calls to context.execute() here emit the given string to the
-  script output.
+    Calls to context.execute() here emit the given string to the
+    script output.
+
+    """
+    url = config.get_main_option("sqlalchemy.url")
+    context.configure(
+        url=url,
+        target_metadata=target_metadata,
+        literal_binds=True,
+        dialect_opts={"paramstyle": "named"},
+    )
+
+    with context.begin_transaction():
+        context.run_migrations()
 
-  """
-  url = config.get_main_option("sqlalchemy.url")
-  context.configure(
-    url=url,
-    target_metadata=target_metadata,
-    literal_binds=True,
-    dialect_opts={"paramstyle": "named"},
-    # --- MODIFICATION FOR PRAXIS ---
-    # compare_type=True enables detection of column type changes.
-    # include_schemas=True if you use multiple schemas (default is usually public)
-    compare_type=True,
-    # --- END MODIFICATION ---
-  )
 
-  with context.begin_transaction():
-    context.run_migrations()
+import os
 
 
 def run_migrations_online() -> None:
-  """Run migrations in 'online' mode.
+    """Run migrations in 'online' mode.
 
-  In this scenario we need to create an Engine
-  and associate a connection with the context.
+    In this scenario we need to create an Engine
+    and associate a connection with the context.
 
-  """
-  connectable = engine_from_config(
-    config.get_section(config.config_ini_section, {}),
-    prefix="sqlalchemy.",
-    poolclass=pool.NullPool,
+    """
+  # --- MODIFICATION FOR PRAXIS ---
+  # Get the database URL from the environment variable
+  praxis_database_url = os.getenv(
+    "PRAXIS_DATABASE_URL",
+    "postgresql://test_user:test_password@localhost:5433/test_db",
   )
+  if praxis_database_url:
+    config.set_main_option("sqlalchemy.url", praxis_database_url)
+  # --- END MODIFICATION ---
 
-  with connectable.connect() as connection:
-    context.configure(
-      connection=connection,
-      target_metadata=target_metadata,
-      # --- MODIFICATION FOR PRAXIS ---
-      compare_type=True,  # For detecting column type changes
-      # include_schemas=True, # If you use multiple schemas
-      # --- END MODIFICATION ---
+    connectable = engine_from_config(
+        config.get_section(config.config_ini_section, {}),
+        prefix="sqlalchemy.",
+        poolclass=pool.NullPool,
     )
 
-    with context.begin_transaction():
-      context.run_migrations()
+    with connectable.connect() as connection:
+        context.configure(
+            connection=connection, target_metadata=target_metadata
+        )
+
+        with context.begin_transaction():
+            context.run_migrations()
 
 
 if context.is_offline_mode():
-  run_migrations_offline()
+    run_migrations_offline()
 else:
-  run_migrations_online()
+    run_migrations_online()
diff --git a/alembic/versions/3a1fe0851e06_make_resourceorm_resource_definition_.py b/alembic/versions/3a1fe0851e06_make_resourceorm_resource_definition_.py
deleted file mode 100644
index 1e6cd01..0000000
--- a/alembic/versions/3a1fe0851e06_make_resourceorm_resource_definition_.py
+++ /dev/null
@@ -1,39 +0,0 @@
-"""Make ResourceOrm.resource_definition_accession_id nullable
-
-Revision ID: 3a1fe0851e06
-Revises:
-Create Date: 2025-11-10 18:42:40.749914
-
-"""
-
-from collections.abc import Sequence
-
-import sqlalchemy as sa
-
-from alembic import op
-
-# revision identifiers, used by Alembic.
-revision: str = "3a1fe0851e06"
-down_revision: str | Sequence[str] | None = None
-branch_labels: str | Sequence[str] | None = None
-depends_on: str | Sequence[str] | None = None
-
-
-def upgrade() -> None:
-  """Make resource_definition_accession_id nullable to work around MappedAsDataclass FK issue."""
-  op.alter_column(
-    "resources",
-    "resource_definition_accession_id",
-    nullable=True,
-    existing_type=sa.UUID(),
-  )
-
-
-def downgrade() -> None:
-  """Revert resource_definition_accession_id to NOT NULL."""
-  op.alter_column(
-    "resources",
-    "resource_definition_accession_id",
-    nullable=False,
-    existing_type=sa.UUID(),
-  )
diff --git a/praxis/backend/core/scheduler.py b/praxis/backend/core/scheduler.py
index 1635654..ad29d1c 100644
--- a/praxis/backend/core/scheduler.py
+++ b/praxis/backend/core/scheduler.py
@@ -158,18 +158,21 @@ class ProtocolScheduler:
     try:
       for requirement in requirements:
         asset_key = f"{requirement.asset_type}:{requirement.asset_definition.name}"
-        if asset_key not in self._asset_reservations:
-          self._asset_reservations[asset_key] = set()
+        if hasattr(requirement.asset_definition, "infinite_consumables") and requirement.asset_definition.infinite_consumables:
+          logger.info("Asset %s is an infinite consumable, skipping reservation check.", asset_key)
+        else:
+          if asset_key not in self._asset_reservations:
+            self._asset_reservations[asset_key] = set()
 
-        if self._asset_reservations[asset_key]:
-          error_msg = (
-            f"Asset {asset_key} is already reserved by runs: {self._asset_reservations[asset_key]}"
-          )
-          logger.warning(error_msg)
-          await self._release_reservations(reserved_assets, protocol_run_id)
-          raise AssetAcquisitionError(error_msg)
+          if self._asset_reservations[asset_key]:
+            error_msg = (
+              f"Asset {asset_key} is already reserved by runs: {self._asset_reservations[asset_key]}"
+            )
+            logger.warning(error_msg)
+            await self._release_reservations(reserved_assets, protocol_run_id)
+            raise AssetAcquisitionError(error_msg)
 
-        self._asset_reservations[asset_key].add(protocol_run_id)
+          self._asset_reservations[asset_key].add(protocol_run_id)
         requirement.reservation_id = uuid.uuid4()
         reserved_assets.append(asset_key)
         logger.debug(
diff --git a/praxis/backend/models/orm/asset.py b/praxis/backend/models/orm/asset.py
index 4ffa174..96099bf 100644
--- a/praxis/backend/models/orm/asset.py
+++ b/praxis/backend/models/orm/asset.py
@@ -9,7 +9,7 @@ including:
 
 from typing import TYPE_CHECKING, ClassVar
 
-from sqlalchemy import JSON, Enum, String
+from sqlalchemy import JSON, Boolean, Enum, String
 from sqlalchemy.dialects.postgresql import JSONB
 from sqlalchemy.orm import Mapped, mapped_column, relationship
 
@@ -73,6 +73,12 @@ class AssetOrm(Base):
     comment="PLR definition of the asset, if applicable.",
     default=None,
   )
+  infinite_consumables: Mapped[bool] = mapped_column(
+    Boolean,
+    nullable=False,
+    default=False,
+    comment="If true, this consumable asset is considered infinite and not tracked.",
+  )
 
   asset_reservations: Mapped[list["AssetReservationOrm"]] = relationship(
     "AssetReservationOrm",
diff --git a/praxis/backend/models/pydantic_internals/protocol.py b/praxis/backend/models/pydantic_internals/protocol.py
index 5510fd0..e0e483f 100644
--- a/praxis/backend/models/pydantic_internals/protocol.py
+++ b/praxis/backend/models/pydantic_internals/protocol.py
@@ -204,6 +204,7 @@ class AssetRequirementModel(BaseModel):
   location_constraints: LocationConstraintsModel = Field(
     default_factory=LocationConstraintsModel,
   )
+  infinite_consumables: bool = False
 
 
 class FunctionProtocolDefinitionBase(BaseModel):
diff --git a/tests/core/test_infinite_consumables.py b/tests/core/test_infinite_consumables.py
new file mode 100644
index 0000000..dbbb885
--- /dev/null
+++ b/tests/core/test_infinite_consumables.py
@@ -0,0 +1,46 @@
+"""Tests for infinite consumables feature."""
+
+from unittest.mock import Mock
+
+import pytest
+
+from praxis.backend.core.scheduler import ProtocolScheduler
+from praxis.backend.models.pydantic_internals.runtime import RuntimeAssetRequirement
+from praxis.backend.utils.errors import AssetAcquisitionError
+from praxis.backend.utils.uuid import uuid7
+
+
+class TestInfiniteConsumables:
+
+    """Tests for infinite consumables feature."""
+
+    @pytest.mark.asyncio
+    async def test_reserve_infinite_consumable_succeeds(self) -> None:
+        """Test that reserving an infinite consumable asset succeeds even if
+        it's already reserved."""
+        scheduler = ProtocolScheduler(
+            db_session_factory=Mock(),
+            task_queue=Mock(),
+            protocol_run_service=Mock(),
+            protocol_definition_service=Mock(),
+        )
+
+        mock_asset_def = Mock()
+        mock_asset_def.infinite_consumables = True
+        mock_asset_def.name = "test_asset"
+        runtime_requirement = RuntimeAssetRequirement(
+            asset_definition=mock_asset_def,
+            asset_type="asset",
+            estimated_duration_ms=None,
+            priority=1,
+        )
+
+        # Reserve for first run
+        first_run_id = uuid7()
+        result1 = await scheduler.reserve_assets([runtime_requirement], first_run_id)
+        assert result1 is True
+
+        # Reserve for second run - should succeed
+        second_run_id = uuid7()
+        result2 = await scheduler.reserve_assets([runtime_requirement], second_run_id)
+        assert result2 is True

